{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sYJU2auR0fFy"
      },
      "source": [
        "# Deep Q-Network (DQN)\n",
        "---\n",
        "In this notebook, you will implement a DQN agent with OpenAI Gym's LunarLander-v2 environment.\n",
        "\n",
        "### 1. Import the Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0waPl13e1K8i",
        "outputId": "91c7021d-b60f-4e89-da9c-398dfa836e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.9 [784 kB]\n",
            "Fetched 784 kB in 1s (1,055 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install xvfb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TefVGPmP0fF2",
        "outputId": "86d33255-04b4-4917-c216-832981379a35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/82/04e9aaf603fdbaecb4323b9e723f13c92c245f6ab2902195c53987848c78/pip-21.1.2-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 5.0MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-21.1.2\n",
            "Collecting box2d\n",
            "  Downloading Box2D-2.3.10-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 6.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d\n",
            "Successfully installed box2d-2.3.10\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-2.2-py3-none-any.whl (15 kB)\n",
            "Collecting EasyProcess\n",
            "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-2.2\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "!python -m pip install --upgrade pip\n",
        "!pip3 install box2d\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "!python -m pip install pyvirtualdisplay\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "is_ipython = 'inline' in plt.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Of16RRNN0fF3"
      },
      "source": [
        "### 2. Instantiate the Environment and Agent\n",
        "\n",
        "Initialize the environment in the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fV9i8i2YkRbO"
      },
      "outputs": [],
      "source": [
        "seed = 2023 # Do not change this\n",
        "def fix(env, seed):\n",
        "  env.seed(seed)\n",
        "  env.action_space.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.set_deterministic(True)\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ammV4_A-0fF3",
        "outputId": "f454e494-d2e1-41e7-ca47-53f7f2039cd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State shape:  (8,)\n",
            "Number of actions:  4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead\n",
            "  \"torch.set_deterministic is deprecated and will be removed in a future \"\n"
          ]
        }
      ],
      "source": [
        "env = gym.make('LunarLander-v2')\n",
        "print('State shape: ', env.observation_space.shape)\n",
        "print('Number of actions: ', env.action_space.n)\n",
        "fix(env, seed)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MzJM7lLS0fF5"
      },
      "source": [
        "Before running the next code cell, familiarize yourself with the code in **Step 2** and **Step 3** of this notebook, along with the code in `dqn_agent.py` and `model.py`.  Once you have an understanding of how the different files work together, \n",
        "- Define a neural network architecture in `model.py` that maps states to action values.  This file is mostly empty - it's up to you to define your own deep Q-network!\n",
        "- Finish the `learn` method in the `Agent` class in `dqn_agent.py`.  The sampled batch of experience tuples is already provided for you; you need only use the local and target Q-networks to compute the loss, before taking a step towards minimizing the loss.\n",
        "\n",
        "Once you have completed the code in `dqn_agent.py` and `model.py`, run the code cell below.  (_If you end up needing to make multiple changes and get unexpected behavior, please restart the kernel and run the cells from the beginning of the notebook!_)\n",
        "\n",
        "You can find the solution files, along with saved model weights for a trained agent, in the `solution/` folder.  (_Note that there are many ways to solve this exercise, and the \"solution\" is just one way of approaching the problem, to yield a trained agent._)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "IEteplxT0fF6",
        "outputId": "ca1fccf1-5d9d-4b84-e1dd-53441e67065b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from dqn_agent import Agent\n",
        "\n",
        "agent = Agent(state_size=8, action_size=4, seed=seed)\n",
        "\n",
        "# watch an untrained agent\n",
        "state = env.reset()\n",
        "img = plt.imshow(env.render(mode='rgb_array'))\n",
        "for j in range(200):\n",
        "    action = agent.act(state, eps = 0.)\n",
        "    img.set_data(env.render(mode='rgb_array')) \n",
        "    plt.axis('off')\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    state, reward, done, _ = env.step(action)\n",
        "    if done:\n",
        "        break\n",
        "        \n",
        "env.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4ag9XaNE0fF7"
      },
      "source": [
        "### 3. Train the Agent with DQN\n",
        "\n",
        "Run the code cell below to train the agent from scratch.  You are welcome to amend the supplied values of the parameters in the function, to try to see if you can get better performance!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSag-PyQ0fF8",
        "outputId": "c5b2d3cf-706f-4352-9e0c-8ae090d1d868"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead\n",
            "  \"torch.set_deterministic is deprecated and will be removed in a future \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 100\tAverage Score: -104.60\n",
            "Episode 196\tAverage Score: -18.34"
          ]
        }
      ],
      "source": [
        "fix(env, 543)\n",
        "#agent.network.eval()  # 測試前先將 network 切換為 evaluation 模式\n",
        "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
        "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
        "    \"\"\"Deep Q-Learning.\n",
        "    \n",
        "    Params\n",
        "    ======\n",
        "        n_episodes (int): maximum number of training episodes\n",
        "        max_t (int): maximum number of timesteps per episode\n",
        "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
        "        eps_end (float): minimum value of epsilon\n",
        "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
        "    \"\"\"\n",
        "    scores = []                        # list containing scores from each episode\n",
        "    scores_window = deque(maxlen=100)  # last 100 scores\n",
        "    eps = eps_start                    # initialize epsilon\n",
        "    for i_episode in range(1, n_episodes+1):\n",
        "        state = env.reset()\n",
        "        score = 0\n",
        "        for t in range(max_t):\n",
        "            action = agent.act(state, eps)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            agent.step(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "            score += reward\n",
        "            if done:\n",
        "                break \n",
        "        scores_window.append(score)       # save most recent score\n",
        "        scores.append(score)              # save most recent score\n",
        "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
        "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
        "        if i_episode % 100 == 0:\n",
        "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
        "        if np.mean(scores_window)>=310.0:\n",
        "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
        "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
        "            break\n",
        "    return scores\n",
        "\n",
        "scores = dqn()\n",
        "\n",
        "# plot the scores\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.plot(np.arange(len(scores)), scores)\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Episode #')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UyukZ26d0fF9"
      },
      "source": [
        "### 4. Watch a Smart Agent!\n",
        "\n",
        "In the next code cell, you will load the trained weights from file to watch a smart agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "x9wMNHWw0fF9",
        "outputId": "f93cfe13-9552-466d-f46f-ea553ae8942f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# load the weights from file\n",
        "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
        "\n",
        "for i in range(3):\n",
        "    state = env.reset()\n",
        "    img = plt.imshow(env.render(mode='rgb_array'))\n",
        "    for j in range(200):\n",
        "        action = agent.act(state)\n",
        "        img.set_data(env.render(mode='rgb_array')) \n",
        "        plt.axis('off')\n",
        "        display.display(plt.gcf())\n",
        "        display.clear_output(wait=True)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        if done:\n",
        "            break\n",
        "            \n",
        "env.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dfgEN-8M0fF-"
      },
      "source": [
        "### 5. Explore\n",
        "\n",
        "In this exercise, you have implemented a DQN agent and demonstrated how to use it to solve an OpenAI Gym environment.  To continue your learning, you are encouraged to complete any (or all!) of the following tasks:\n",
        "- Amend the various hyperparameters and network architecture to see if you can get your agent to solve the environment faster.  Once you build intuition for the hyperparameters that work well with this environment, try solving a different OpenAI Gym task with discrete actions!\n",
        "- You may like to implement some improvements such as prioritized experience replay, Double DQN, or Dueling DQN! \n",
        "- Write a blog post explaining the intuition behind the DQN algorithm and demonstrating how to use it to solve an RL environment of your choosing.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yFuUKKRYH73"
      },
      "outputs": [],
      "source": [
        "fix(env, 543)\n",
        "#agent.network.eval()  # 測試前先將 network 切換為 evaluation 模式\n",
        "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
        "\n",
        "NUM_OF_TEST = 5 # Do not revise it !!!!!\n",
        "test_total_reward = []\n",
        "action_list = []\n",
        "for i in range(NUM_OF_TEST):\n",
        "  actions = []\n",
        "  state = env.reset()\n",
        "\n",
        "  img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "  total_reward = 0\n",
        "\n",
        "  done = False\n",
        "  while not done:\n",
        "      #state, action, reward, _, done = agent.memory.sample()\n",
        "      action = agent.act(state)\n",
        "\n",
        "      actions.append(action)\n",
        "      state, reward, done, _ = env.step(action)\n",
        "\n",
        "      total_reward += reward\n",
        "\n",
        "      #img.set_data(env.render(mode='rgb_array'))\n",
        "      #display.display(plt.gcf())\n",
        "      #display.clear_output(wait=True)\n",
        "  print(total_reward)\n",
        "  test_total_reward.append(total_reward)\n",
        "\n",
        "  action_list.append(actions) #儲存你測試的結果\n",
        "  print(\"length of actions is \", len(actions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZsMkGmIY42b"
      },
      "outputs": [],
      "source": [
        "PATH = \"Action_List_test.npy\" # 可以改成你想取的名字或路徑\n",
        "np.save(PATH ,np.array(action_list)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-CqyhHzaWAL"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U69c-YTxaw6b"
      },
      "outputs": [],
      "source": [
        "action_list = np.load(PATH,allow_pickle=True) #到時候你上傳的檔案\n",
        "seed = 543 #到時候測試的seed 請不要更改\n",
        "fix(env, seed)\n",
        "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
        "\n",
        "\n",
        "#agent.network.eval()  # 測試前先將 network 切換為 evaluation 模式\n",
        "\n",
        "test_total_reward = []\n",
        "for actions in action_list:\n",
        "  state = env.reset()\n",
        "  img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "  total_reward = 0\n",
        "\n",
        "  done = False\n",
        "  # while not done:\n",
        "  done_count = 0\n",
        "  for action in actions:\n",
        "      # action, _ = agent1.sample(state)\n",
        "      state, reward, done, _ = env.step(action)\n",
        "      done_count += 1\n",
        "      total_reward += reward\n",
        "      if done:\n",
        "        \n",
        "        break\n",
        "    #   img.set_data(env.render(mode='rgb_array'))\n",
        "    #   display.display(plt.gcf())\n",
        "    #   display.clear_output(wait=True)\n",
        "  print(f\"Your reward is : %.2f\"%total_reward)\n",
        "  test_total_reward.append(total_reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpJpZz3Wbm0X"
      },
      "outputs": [],
      "source": [
        "print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Deep_Q_Network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
